# Задание 1
Требования 
1. Создайте 3 виртуальных диска, объемом по 1ГБ.
2. Разметьте созданные диски
	- Разметьте disk1.img в формате MBR, создайте один раздел и отформатируйте его в ext4. 
	- Разметьте disk2.img в формате GPT, создайте два раздела: xfs и btrfs.
	- Используйте parted для гибкой разметки третьего диска.
3. Настройка файловой системы 
	- После создания файловой системы на одном из дисков (например, btrfs), измените настройки inodes, если файловая система это позволяет.
	- Выполните команды для проверки состояния файловой системы.
## 1. Создание виртуальных дисков 1Гб
```
dd if=/dev/zero of=disk1.img bs=1M count=1024
dd if=/dev/zero of=disk2.img bs=1M count=1024
dd if=/dev/zero of=disk3.img bs=1M count=1024
```
## 2. Разметка дисков
### disk1.img (MBR, один раздел ext4)
```
# Создаем loop-устройство
sudo losetup -fP disk1.img

# Находим имя loop-устройства (обычно /dev/loop0 или подобное)
LOOP_DEV=$(losetup -l | grep disk1.img | awk '{print $1}')

# Размечаем диск в MBR
echo -e "n\np\n1\n\n\nw" | sudo fdisk $LOOP_DEV

# Обновляем информацию о разделах
sudo partprobe $LOOP_DEV

# Форматируем раздел в ext4
sudo mkfs.ext4 "${LOOP_DEV}p1"

# Отключаем loop-устройство
sudo losetup -d $LOOP_DEV
```
### disk2.img (GPT, два раздела: xfs и btrfs)
```
# Создаем loop-устройство
sudo losetup -fP disk2.img
LOOP_DEV=$(losetup -l | grep disk2.img | awk '{print $1}')

# Создаем GPT таблицу
sudo parted $LOOP_DEV mklabel gpt

# Создаем первый раздел (xfs)
sudo parted $LOOP_DEV mkpart primary xfs 1MiB 512MiB

# Создаем второй раздел (btrfs)
sudo parted $LOOP_DEV mkpart primary btrfs 512MiB 100%

# Форматируем разделы
sudo mkfs.xfs "${LOOP_DEV}p1"
sudo mkfs.btrfs "${LOOP_DEV}p2"

# Отключаем loop-устройство
sudo losetup -d $LOOP_DEV
```
### disk3.img с помощью parted (гибкая разметка)
```
# Создаем loop-устройство
sudo losetup -fP disk3.img
LOOP_DEV=$(losetup -l | grep disk3.img | awk '{print $1}')

# Запускаем parted в интерактивном режиме
sudo parted $LOOP_DEV

# В интерактивном режиме parted выполняем:
# mklabel msdos               # Создаем MBR таблицу
# mkpart primary ext4 1MiB 500MiB
# mkpart primary ntfs 500MiB 100%
# quit

# После выхода из parted форматируем разделы
sudo mkfs.ext4 "${LOOP_DEV}p1"
sudo mkfs.ntfs "${LOOP_DEV}p2"

# Отключаем loop-устройство
sudo losetup -d $LOOP_DEV
```
## 3. Настройка файловой системы (изменение inodes для btrfs)
```
# Подключаем disk2.img для работы с btrfs
sudo losetup -fP disk2.img
LOOP_DEV=$(losetup -l | grep disk2.img | awk '{print $1}')

# Монтируем btrfs раздел
sudo mkdir -p /mnt/btrfs_test
sudo mount "${LOOP_DEV}p2" /mnt/btrfs_test

# Для btrfs inodes создаются динамически, поэтому их количество нельзя задать при создании.
# Но мы можем проверить текущее состояние:
sudo btrfs filesystem show /mnt/btrfs_test
sudo btrfs filesystem df /mnt/btrfs_test
sudo btrfs filesystem usage /mnt/btrfs_test

# Размонтируем
sudo umount /mnt/btrfs_test
sudo losetup -d $LOOP_DEV
```
## 4. Проверка состояния файловых систем
```
# Для disk1.img (ext4)
sudo losetup -fP disk1.img
LOOP_DEV=$(losetup -l | grep disk1.img | awk '{print $1}')
sudo fsck.ext4 -f "${LOOP_DEV}p1"
sudo dumpe2fs "${LOOP_DEV}p1" | grep -i inode
sudo losetup -d $LOOP_DEV

# Для disk2.img (xfs и btrfs)
sudo losetup -fP disk2.img
LOOP_DEV=$(losetup -l | grep disk2.img | awk '{print $1}')
sudo xfs_repair -n "${LOOP_DEV}p1"
sudo btrfs check "${LOOP_DEV}p2"
sudo losetup -d $LOOP_DEV

# Для disk3.img (ext4 и ntfs)
sudo losetup -fP disk3.img
LOOP_DEV=$(losetup -l | grep disk3.img | awk '{print $1}')
sudo fsck.ext4 -f "${LOOP_DEV}p1"
sudo ntfsfix "${LOOP_DEV}p2"
sudo losetup -d $LOOP_DEV
```

```
ls -la disk1.img disk2.img disk3.img
fdisk -l disk1.img disk2.img disk3.img
```

![[CleanShot 2025-07-09 at 17.24.27.png]]

![[CleanShot 2025-07-09 at 17.19.00@2x.png]]
![[CleanShot 2025-07-09 at 17.20.15.png]]
![[CleanShot 2025-07-09 at 17.23.56.png]]
# Задание 2 
Требования 
1. Ручное монтирование
	- Смонтируйте созданные разделы в директории /mnt/disk1, /mnt/disk2, Imnt/disk3. 
	- Проверьте доступность дисков через Isblk и df -h.
2. Автоматическое монтирование 
	- Добавьте записи для каждого диска в файл /etc/fstab 
	- Перезагрузите систему и проверьте, что диски автоматически монтируются.
## 1. Ручное монтирование

### Создаем точки монтирования
```
sudo mkdir -p /mnt/disk{1,2,3}
```
### Монтируем диски

#### Для disk1.img (ext4)
```
sudo losetup -fP disk1.img
LOOP_DEV=$(losetup -l | grep disk1.img | awk '{print $1}')
sudo mount "${LOOP_DEV}p1" /mnt/disk1
```
#### Для disk2.img (xfs и btrfs)
```
sudo losetup -fP disk2.img
LOOP_DEV=$(losetup -l | grep disk2.img | awk '{print $1}')

# Создаем поддиректории для каждого раздела

sudo mkdir -p /mnt/disk2/xfs
sudo mkdir -p /mnt/disk2/btrfs

# Монтируем разделы
sudo mount "${LOOP_DEV}p1" /mnt/disk2/xfs
sudo mount "${LOOP_DEV}p2" /mnt/disk2/btrfs
```
#### Для disk3.img (ext4 и ntfs)
```
sudo losetup -fP disk3.img
LOOP_DEV=$(losetup -l | grep disk3.img | awk '{print $1}')

# Создаем поддиректории для каждого раздела
sudo mkdir -p /mnt/disk3/ext4
sudo mkdir -p /mnt/disk3/ntfs

# Монтируем разделы
sudo mount "${LOOP_DEV}p1" /mnt/disk3/ext4
sudo mount -t ntfs-3g "${LOOP_DEV}p2" /mnt/disk3/ntfs
```
### Проверяем доступность дисков
```
lsblk
df -h
```
## 2. Автоматическое монтирование через /etc/fstab

### Определяем UUID разделов
```
sudo blkid
```
### Редактируем /etc/fstab
```
sudo nano /etc/fstab
```
Добавляем следующие строки (замените UUID на реальные значения из вывода blkid):
```
# Disk1 - ext4
UUID=<UUID_disk1p1> /mnt/disk1 ext4 defaults 0 2

# Disk2 - xfs
UUID=<UUID_disk2p1> /mnt/disk2/xfs xfs defaults 0 2

# Disk2 - btrfs
UUID=<UUID_disk2p2> /mnt/disk2/btrfs btrfs defaults 0 2

# Disk3 - ext4
UUID=<UUID_disk3p1> /mnt/disk3/ext4 ext4 defaults 0 2

# Disk3 - ntfs
UUID=<UUID_disk3p2> /mnt/disk3/ntfs ntfs-3g defaults 0 2
```
### Проверяем правильность fstab
```
sudo mount -a
```
### Настраиваем автоматическое подключение loop-устройств

Для автоматического подключения образов при загрузке создадим systemd unit:
```
sudo nano /etc/systemd/system/loop-setup.service
```
Добавляем содержимое:
```
[Unit]
Description=Setup loop devices
Before=local-fs.target

[Service]
Type=oneshot
ExecStart=/usr/bin/losetup -fP /path/to/disk1.img
ExecStart=/usr/bin/losetup -fP /path/to/disk2.img
ExecStart=/usr/bin/losetup -fP /path/to/disk3.img
RemainAfterExit=yes

[Install]
WantedBy=multi-user.target
```
Активируем сервис:
```
sudo systemctl enable loop-setup.service
sudo systemctl start loop-setup.service
```

![[CleanShot 2025-07-09 at 17.32.25.png]]

![[CleanShot 2025-07-09 at 18.11.00.png]]
# Задание 3
Требования 
1. Просмотр информации о месте 
	- Выполните df -h для анализа свободного и занятого пространства.
	- Создайте несколько крупных файлов (например, 500 МБ, 700 МБ) и найдите их с помощью du: 
2. Поиск больших файлов 
	- Установите и используйте ncdu для анализа использования пространства.
3. Состояние SMART-дисков
	- Проверьте состояние дисков с помощью smartctl
## 1. Анализ использования дискового пространства
### Просмотр информации о занятом месте
```
df -h
```
Эта команда покажет список всех смонтированных файловых систем с информацией о размере, использованном пространстве и доступном месте.
### Создание крупных тестовых файлов
```
# Создаем файлы в разных разделах
sudo dd if=/dev/zero of=/mnt/disk1/large_file1.bin bs=1M count=500
sudo dd if=/dev/zero of=/mnt/disk2/xfs/large_file2.bin bs=1M count=700
sudo dd if=/dev/zero of=/mnt/disk3/ext4/large_file3.bin bs=1M count=300
```
### Поиск больших файлов с помощью du
```

# Просмотр размера файлов в конкретном каталоге
sudo du -ah /mnt/disk1 | sort -rh | head -n 10
sudo du -ah /mnt/disk2/xfs | sort -rh | head -n 10
sudo du -ah /mnt/disk3/ext4 | sort -rh | head -n 10

# Или для всех смонтированных дисков
sudo du -ah /mnt | sort -rh | head -n 20
```
### Установка и использование ncdu
```
# Установка ncdu (если не установлен)
sudo apt install ncdu

# Анализ дискового пространства
sudo ncdu /mnt/disk1
sudo ncdu /mnt/disk2
sudo ncdu /mnt/disk3

# Для выхода из ncdu нажмите 'q'
```
## 2. Проверка состояния SMART-дисков
### Установка smartmontools (если не установлен)
```
sudo apt install smartmontools 
```
### Проверка состояния дисков
```

# Просмотр списка доступных дисков
sudo lsblk

# Проверка SMART-статуса для каждого физического диска
# (замените /dev/sda на ваши реальные устройства)

# Краткая проверка здоровья
sudo smartctl -H /dev/sda

# Подробная информация о диске
sudo smartctl -i /dev/sda

# Полный SMART-атрибуты
sudo smartctl -A /dev/sda

# Запуск теста (может занять время)
sudo smartctl -t short /dev/sda  # Быстрый тест
sudo smartctl -t long /dev/sda   # Длительный тест

# Просмотр результатов теста
sudo smartctl -l selftest /dev/sda
```
### Проверка виртуальных дисков (loop-устройств)
Для виртуальных дисков SMART-данные недоступны, так как это файлы, а не физические устройства. Однако можно проверить базовые параметры:
```
# Для loop-устройств
sudo losetup -l
LOOP_DEV=$(losetup -l | grep disk1.img | awk '{print $1}')
sudo hdparm -I $LOOP_DEV
```

![[CleanShot 2025-07-09 at 18.38.09.png]]
![[CleanShot 2025-07-09 at 18.30.20.png]]
![[CleanShot 2025-07-09 at 18.37.19.png]]
# Задание 4
Требования 
1. Опции монтирования 
	- Настройте разные точки монтирования с опциями. Только для чтения (го). Без кеширования (sync). Ограничение выполнения файлов (nоехес).
2. Настройка квот.
	- Включите поддержку квот на одном из дисков.
	- Создайте пользователей и назначьте им квоты.
## 1. Настройка опций монтирования
### Подготовка точек монтирования
```
sudo mkdir -p /mnt/{disk1_ro,disk2_sync,disk3_noexec}
```
### Монтирование с разными опциями
#### Только для чтения (ro)
```
sudo mount -o ro /dev/loop5p1 /mnt/disk1_ro
```
#### Без кеширования (sync)
```
sudo mount -o sync /dev/loop6p1 /mnt/disk2_sync
```
#### Без выполнения файлов (noexec)
```
sudo mount -o noexec /dev/loop7p1 /mnt/disk3_noexec
```
### Проверка опций монтирования
```
mount | grep -E 'disk1_ro|disk2_sync|disk3_noexec'
```
## 2. Настройка квот
### Выберем для квот /mnt/disk1 (ext4)
### Включение поддержки квот
```
# Размонтируем диск
sudo umount /mnt/disk1

# Добавляем опции квот в файловую систему
sudo tune2fs -O quota /dev/loop5p1

# Монтируем с опциями квот
sudo mount -o usrquota,grpquota /dev/loop5p1 /mnt/disk1

# Проверяем
mount | grep loop5p1
```
### Выберем для квот /mnt/disk1 (ext4)
### Включение поддержки квот
```
# Размонтируем диск
sudo umount /mnt/disk1

# Добавляем опции квот в файловую систему
sudo tune2fs -O quota /dev/loop5p1

# Монтируем с опциями квот
sudo mount -o usrquota,grpquota /dev/loop5p1 /mnt/disk1

# Проверяем
mount | grep loop5p1
```
### Установка необходимых пакетов
```
# Для Debian/Ubuntu
sudo apt install quota
```
### Инициализация квот
```
sudo quotacheck -cum /mnt/disk1
sudo quotaon /mnt/disk1
```
### Создание тестовых пользователей
```
sudo useradd user1
sudo passwd user1
sudo usermod -aG sudo user1
```
### Назначение квот
```
# Установка квот для user1 (1GB мягкий лимит, 1.1GB жесткий лимит)
sudo setquota -u user1 1G 1.1G 0 0 /mnt/disk1

# Установка квот для user2 (500MB мягкий лимит, 550MB жесткий лимит)
sudo setquota -u user2 500M 550M 0 0 /mnt/disk1

# Проверка квот

sudo repquota -a
```
### Тестирование квот
```
# Переключаемся на user1
sudo su - user1

# Создаем файл для теста
dd if=/dev/zero of=/mnt/disk1/user1_testfile bs=1M count=1024

# Попытка превысить лимит (должна вызвать ошибку)
dd if=/dev/zero of=/mnt/disk1/user1_testfile2 bs=1M count=200

# Выходим из-под user1
exit
```
### Автоматическое включение квот при загрузке
Добавьте в /etc/fstab для /mnt/disk1 опции `usrquota,grpquota`:
```
UUID=<UUID-loop5p1> /mnt/disk1 ext4 defaults,usrquota,grpquota 0 2
```
### Просмотр информации о квотах
```
# Для конкретного пользователя
sudo quota -u user1

# Для всех пользователей
sudo repquota /mnt/disk1
```
![[CleanShot 2025-07-09 at 21.45.29.png]]
![[CleanShot 2025-07-09 at 22.30.02.png]]
![[CleanShot 2025-07-09 at 22.29.10.png]]
![[CleanShot 2025-07-09 at 22.43.23.png]]
# Задание 5 
Требования
1. Измерение скорости записи 
	- Для каждой файловой системы выполните тест записи.
2. Сравнение скорости чтения
	- Выполните тесты чтения
3. Тестирование устойчивости к аварийной перезагрузке 
	- Создайте файлы на каждом диске.
	- Сделайте аварийную перезагрузку.
	- Проверьте целостность данных после перезагрузки с помощью утилит.
4. Отчет о нагрузке 
	- Используйте iostat для анализа нагрузки на диски

## 1. Измерение скорости записи
### Подготовка тестовых файлов (по 1 ГБ для каждого диска)
```
for i in {1..3}; do
  echo "Тестирование записи на disk$i..."
  sync; dd if=/dev/zero of=/mnt/disk$i/testfile bs=1M count=1024 oflag=direct status=progress
  echo "----------------------------------"
done
```
### Альтернативный тест с помощью `fio` (более точный)
```
sudo apt install fio  # Установка если необходимо

for i in {1..3}; do
  echo "Тестирование последовательной записи на disk$i..."
  sudo fio --name=write_test --directory=/mnt/disk$i --size=1G --rw=write --bs=1M --direct=1 --numjobs=1 --runtime=60 --time_based --group_reporting
  echo "----------------------------------"
done
```
## 2. Сравнение скорости чтения
### Тест последовательного чтения
```
for i in {1..3}; do
  echo "Тестирование чтения с disk$i..."
  sync; echo 3 | sudo tee /proc/sys/vm/drop_caches
  dd if=/mnt/disk$i/testfile of=/dev/null bs=1M status=progress
  echo "----------------------------------"
done
```
### Тест случайного чтения с помощью `fio`
```
for i in {1..3}; do
  echo "Тестирование случайного чтения на disk$i..."
  sudo fio --name=randread_test --directory=/mnt/disk$i --size=200M --rw=randread --bs=4k --direct=1 --numjobs=4 --runtime=60 --time_based --group_reporting
  echo "----------------------------------"
done
```
## 3. Тестирование устойчивости к аварийной перезагрузке
### Создание тестовых файлов
```
for i in {1..3}; do
  echo "Создание тестовых файлов на disk$i..."
  sudo mkdir -p /mnt/disk$i/crash_test
  sudo dd if=/dev/urandom of=/mnt/disk$i/crash_test/file1.bin bs=1M count=100
  sudo cp -r /etc /mnt/disk$i/crash_test/etc_backup
  sudo sync
  echo "----------------------------------"
done
```
### Аварийная перезагрузка
```
echo "Выполняем аварийную перезагрузку..."
echo b | sudo tee /proc/sysrq-trigger
```
### После перезагрузки проверяем целостность

#### Для ext4 (disk1 и disk3/ext4)
```
sudo fsck.ext4 -fn /dev/loop5p1
sudo fsck.ext4 -fn /dev/loop7p1
```
#### Для xfs (disk2/xfs)
```
sudo xfs_repair -n /dev/loop6p1
```
#### Для btrfs (disk2/btrfs)
```
sudo btrfs check /dev/loop6p2
```
#### Для ntfs (disk3/ntfs)
```
sudo ntfsfix -n /dev/loop7p2
```
#### Проверка содержимого файлов
```
for i in {1..3}; do
  echo "Проверка содержимого на disk$i..."
  ls -lh /mnt/disk$i/crash_test/
  sudo diff -r /etc /mnt/disk$i/crash_test/etc_backup | head -n 20
  echo "----------------------------------"
done
```
## 4. Отчет о нагрузке с помощью `iostat`
### Мониторинг нагрузки в реальном времени
```
# Установка sysstat если необходимо
sudo apt install sysstat

# Запуск мониторинга для всех дисков
iostat -x -d 1 | grep -E 'loop5|loop6|loop7'
```
### Тест под нагрузкой с записью отчета в файл
```
# Запускаем iostat в фоне
iostat -x -d 1 > iostat_report.txt &

# Запускаем нагрузочный тест
for i in {1..3}; do
  sudo fio --name=load_test --directory=/mnt/disk$i --size=100M --rw=randrw --bs=4k --direct=1 --numjobs=6 --runtime=120 --time_based --group_reporting
done

# Останавливаем iostat
killall iostat

# Анализ отчета
grep -A1 'Device' iostat_report.txt | grep -E 'loop5|loop6|loop7'
```
### Генерация сводного отчета
```
echo "Сводный отчет о производительности:"
echo "Файловая система | Скорость записи | Скорость чтения | Устойчивость"
echo "------------------------------------------------------------------"
for i in {1..3}; do
  fs_type=$(df -T /mnt/disk$i | tail -1 | awk '{print $2}')
  write_speed=$(grep "disk$i" iostat_report.txt | awk '{sum+=$3} END {print sum/NR " MB/s"}')
  read_speed=$(grep "disk$i" iostat_report.txt | awk '{sum+=$4} END {print sum/NR " MB/s"}')
  integrity=$(sudo fsck -n /dev/loop${4+i}p1 2>&1 | grep -c "clean" | awk '{print $1?"OK":"ERROR"}')
  echo "disk$i ($fs_type) | $write_speed | $read_speed | $integrity"
done
```


![[CleanShot 2025-07-09 at 23.04.35.png]]
![[CleanShot 2025-07-09 at 23.05.00.png]]
![[CleanShot 2025-07-09 at 23.05.11.png]]

![[CleanShot 2025-07-09 at 23.17.44.png]]
![[CleanShot 2025-07-09 at 23.17.32.png]]
![[CleanShot 2025-07-09 at 23.17.18.png]]

![[CleanShot 2025-07-09 at 23.40.38.png]]
![[CleanShot 2025-07-09 at 23.43.59.png]]
